/**
 * http报文结构是怎样的
 * 
 * 对tcp而言，在传输的时候分为两部分：TCP头和数据部分
 * 
 * 而http类似，也是header + body 结构，具体而言：
 * 
 * 起始行 + 头部 + 空行 + 实体
 * 
 * 由于http请求报文和响应报文是由区别的，因此我们分开介绍
 * 
 * 起始行
 * 
 * 对于请求报文来说，起始行类似下面这样：
 * 
 * GET /home HTTP/1.1
 * 
 * 也就是方法 + 路径 + http版本
 * 
 * 
 * 对于响应报文来说，起始行一般是这样的：
 * HTTP/1.1 200 OK
 * 
 * 响应报文的起始行也叫做状态行。由http版本、状态码和原因三部分组成
 * 
 * 值得注意的是，其实行中，每两个部分之间用空格隔开，最后一部分后面应该接一个换行，严格遵循ABNF语法规范
 * 
 * 头部
 * 
 * 展示一下请求头和响应头在报文中的位置
 * 
 * 请求行        Method SP URI SP Version CRLF
 *        ->    Field Name : Field Value CRLF  
 * 请求头-|     .................
 *        ->    Field Name : Field Value CRLF
 * 空行
 * 
 * 
 * 状态行       Version SP Status Code SP Reason CRLF
 *              Field Name : Field Value        CRLF
 * 响应头       ..................
 *              Field Name : Field Value        CRLF
 * 空行
 * 
 * 
 * 不管是请求头还是响应头，其中的字段是相当多的，而且牵扯到http的非常多的特性，重点看看这些头部字段的格式
 * 1.字段名不区分大小写
 * 2.字段名不允许出现空格，不可以出现下划线
 * 3.字段名后面必须紧挨着：
 * 
 * 空行
 * 
 * 很重要，用来区分头部和实体
 * 
 * 问： 如果在头部中间故意加一行空行会怎样
 * 那么空行后面的内容全部被视为实体
 * 
 * 实体
 * 
 * 就是具体的数据了，也就是body部分。请求报文对于请求体，响应报文对于响应体
 * 
 * 如何理解HTTP的请求方法
 * 
 * 有哪些请求方法
 * 
 * http/1.1规定了以下请求方法（注意，都是大写）
 * 
 * GET：通常用来获取资源
 * HEAD:获取资源的元信息
 * POST:提交数据，即上传数据
 * PUT:修改数据
 * DELETE:删除资源（几乎用不到）
 * CONNECT：建立连接隧道，用于代理服务器
 * OPTIONS:列出可对资源实行的请求方法，用来跨域请求
 * TRACE：追踪请求-响应的传输路径
 * 
 * GET和POST由什么区别
 * 
 * 首先最直观的是语义上的区别
 * 
 * 而后又有这样一些具体的差别
 * 
 * ·从缓存的角度，GET请求会被浏览器主动缓存下来，留下历史记录，而POST请求不会
 * ·从编码的角度，GET只能进行URL编码，只能接收ASCII字符，而POST没有限制
 * ·从参数的角度，GET一般放在URL中，因此不安全，POST放在请求体中，更适合传输敏感信息
 * ·从幂等性的角度，GET是幂等的，而POST不是（幂等表示执行相同的操作，结果也是相同的）
 * ·从TCP的角度，GET会把请求报文一次性发出去，而POST会分为两个TCP包，首先发header部分，如果服务器响应100（continue）
 * 然后发body部分，
 * 
 * 如何理解URI
 * 
 * URI 全称统一资源标识符，他的作用很简单，就是区分互联网上不同的资源
 * 
 * 但是，它并不是我们常说的网址，网址是URL，实际上URL包含了URN和URL两个部分，由于URL过于普及，就默认将URI视为URL了
 * 
 * URI的结构
 * 
 * URI真正最完整的结构是这样的
 * 
 * scheme  ://  user:passwd@  host:port  path  ?query  #fragment
 * 
 * scheme表示协议名，比如http，https，file等等。后面必须和://连在一起
 * 
 * user:passwd@ 表示登录主机时的用户信息，不过很不安全，不推荐使用，也不常用
 * 
 * host:port表示主机名和端口
 * 
 * path表示请求路径，标记资源所在的位置
 * 
 * query表示查询参数，为key=val这种形式，多个键值对之间用&隔开
 * 
 * fragment表示URI所定位的资源内的一个锚点，浏览器可以根据这个锚点跳转到对应的位置
 * 
 * https://www.baidu.com/s?wd=HTTP&rsv_spt=1
 * 
 * URI编码
 * 
 * URI只能使用ASCII，ascii之外的字符是不支持显示的，而且还有一部分符号是界定符，如果不加以处理就会导致解析报错
 * 因此，URI引入了编码机制，将所有非ASCII码字符和界定符转换为十六进制字节值，然后再前面加个%
 * 
 * 如空格被转换为%20
 * 
 * 
 * 如何理解http状态码
 * 
 * RFC规定http的状态码为三位数，被分成了5类
 * 
 * ·1xx：表示目前是协议处理的中间状态，还需要后续操作
 * ·2xx：表示成功状态
 * ·3xx：重定向状态，资源位置发生变动，需要重新请求
 * ·4xx：请求报文有误
 * ·5xx：服务器发送错误
 * 
 * 
 * 1xx
 * 
 * 101 switch protocols。在HTTP升级为websocket的时候，如果服务器同意变更，就会发送状态码101
 * 
 * 2xx
 * 
 * 200 ok是见的最多的成功状态码。通常在响应体中放有数据
 * 
 * 204 No Content含义与200相同，但响应头后没有body数据
 * 
 * 206 Partial Content顾名思义，表示部分内容，它的使用场景为HTTP分块下载和断点传输，当然也会带上相应的响应头
 * 字段Content-Range
 * 
 * 3xx
 * 
 * 301 Moved Permanently即永久重定向，对应着302 Found，即临时重定向
 * 比如你的网站从http升级到了https，以前的站点再也不用了，应当返回301，这个时候浏览器会默认做缓存优化，在第二次
 * 访问的时候自动访问重定向的那个位置
 * 
 * 而如果只是暂时不用，那么可以返回302即可，和301不同的是，浏览器并不会做缓存优化
 * 
 * 304 Not Modified 当协商缓存命中的时候返回这个状态码
 * 
 * 4xx
 * 
 * 400 Bad Request：开发者经常一头雾水，只是笼统的提示了以下错误，并不知道哪里出错了
 * 
 * 403 Forbidden：这实际上并不是请求报文出错，而是服务器禁止访问，原因有很多，比如法律禁止、信息敏感
 * 
 * 404 Not Found：资源未找到，表示没有在服务器上找到相应资源
 * 
 * 405 Method Not Allowed：请求方法不被服务端允许
 * 
 * 406 Not Acceptable：资源无法满足客户端的条件
 * 
 * 408 Request timeout：服务器等待了太长时间
 * 
 * 409 Conflict：多个请求发生了冲突
 * 
 * 413 Request Entity Too Large：请求体的数据过大
 * 
 * 414 Request-URI Too Long：请求行的uri太大
 * 
 * 429 Too Many Request 客户端发送的请求太多
 * 
 * 431 Request Header Fields Too Large：请求头的字段内容太大
 * 
 * 5xx
 * 
 * 500 Internal Server Error：仅告诉你服务器出错了，出了啥错咋也不知道
 * 
 * 501 Not Implemented：表示客户端请求的功能还不支持
 * 
 * 502 Bad Gateway：服务器自身是正常的，但访问的时候出错了，啥错咋也不知道
 * 
 * 503 Service Unavailable：表示服务器很忙，暂时无法相应服务
 * 
 * 简要概况以下http的特点？http有哪些缺点
 * 
 * http特点
 * 
 * 1.灵活可扩展，主要体现在两个方面，一个是语义上的自由，只规定了基本格式，比如空格分隔单词，换行分隔字段，其他部分
 * 都没有严格的语法限制。另一个是传统形式的多样性，不仅仅可以传输文本，还能传输图片、视频等任意数据，非常方便
 * 2.可靠传输，http基于tcp/ip，因此把这一特性继承了下来。这属于TCP的特性
 * 3.请求-应答。也就是一收一发、有来有回，当然这个请求方和应答方不单单指客户端和服务器端之间，如果某台服务器作为代理
 * 来连接后端的服务端，那么这台服务器也会扮演请求方的角色
 * 4.无状态。这里的状态是指通信过程中的上下文信息，而每次http请求都是独立的、无关的，默认不需要保留状态信息
 * 
 * http缺点
 * 
 * ·无状态
 * 
 * 所谓的有点和缺点是要分场景来看的，对于http而言，最具争议的地方在于它的无状态
 * 
 * 在需要长连接的场景中，需要保存大量的上下文信息，以免传输大量重复的信息，那么这时候无状态就是http的缺点
 * 但于此同时，另外一些应用仅仅只是为了获取一些数据，不需要保存连接上下文信息，无状态反而减少了网络开销，成为了http的有点
 * 
 * 明文传输
 * 
 * 即协议里的报文（主要指头部）不适用二进制数据，而是文本形式
 * 
 * 这当然对于调试提供了便利，但同时也让http的报文信息暴露给了外界，给攻击者也提供了便利。WIFI陷阱就是利用HTTP明文传输
 * 的缺点，诱导你连上热点，然后疯狂抓取你所有的流量，从而拿到你的敏感信息
 * 
 * 队头阻塞问题
 * 
 * 当http开启长连接时，公用一个tcp连接，同一时刻只能处理一个请求，那么当请求耗时过长的情况下，其他的请求只能
 * 处于阻塞状态，也就是著名的对头阻塞问题
 * 
 * 对Accept系列字段了解多少
 * 
 * 对于Accept系列字段的介绍分为四个部分：数据格式，压缩方式，支持语言，字符集
 * 
 * 数据格式：
 * 
 * 上一节谈到http灵活的特性，它支持非常多的数据格式，那么这么多的数据一起到达客户端，客户端怎么知道他的格式呢？
 * 
 * 当然， 最低效的方法是直接猜，有没有更好的方式呢？直接指定可以码？
 * 
 * 答案是坑定的。不过首先需要介绍一个标准--MIME（Multipurpose Internal Mail Extensions，多用途互联网邮件扩展）
 * 它首先用在电子邮件系统中，让邮件可以发任意类型的数据，这对于http也是通用的
 * 
 * 因此，http从MIME type取一部分用来标记报文body部分的数据类型，这些类型体现在Content-Type这个字段，当然这是针对
 * 与发送端而言的，接收端想要收到特定类型，也可以用Accept字段
 * 
 * 具体而言，这两个字段的取值可以分为下面几类
 * ·text：text/html, text/plain, text/css
 * ·image: image/gif, image/jpeg, image/png等
 * ·audio/video: audio/mpeg, video/mp4等
 * ·application: application/json, application/javascript, application/pdf, application/octet-stream
 * 
 * 压缩方式：
 * 
 * 当然一般这些数据都是会进行编码压缩的，采取什么样的方式就体现了发送方的Content-Encoding字段上，同样的，
 * 接收什么样的压缩方式体现了接收方的Accept-Encoding字段上。这个字段的取值有以下几种
 * ·gzip 当今最流行的压缩方式
 * ·deflact 另外一种著名的压缩方式
 * ·br: 一种专门为http发明的压缩算法
 * 
 * //发送端
 * Content-Encoding: gzip
 * 
 * //接收端
 * Accept-Encoding: gzip
 * 
 * 支持语言：
 * 
 * 对于发送方而言，还有一个Content-Language字段，在需要实现国际化的方案中，可以用来指定支持的语言，在接收方对应的
 * 字段为Accept-Language
 * 
 * //发送端
 * Content-Language: zh-CN, zn, cn
 * 
 * //接收端
 * Accept-Language: zh-CN, zn, cn
 * 
 * 字符集：
 * 
 * 最后一个比较特殊的字段，在接收端对应位Accept-Charset,指定可以接收的字符集，而在发送端并没有对应的Content-Charset
 * 而是直接放在了Content-Type中，以charset属性指定如：
 * 
 * Content-type: text/html; charset=utf-8
 * 
 * //接收端
 * Accept-Charset: utf-8
 * 
 * 
 * 对于定长和不定长的数据，http是怎么传输的
 * 
 * 可以看见Content-Length 对于http传输起到了十分重要的作用，如果设置不挡，可以直接导致传输失败
 * 
 * 不定长包体
 * 
 * 上述是针对定长包体，那么对于不定长包体而言是如何传输的呢
 * 
 * 这就必须介绍另外一个http头部字段了
 * 
 * Transfer-Encoding: chunked
 * 
 * 表示分块传输数据，设置这个字段后自动产生两个效果
 * ·Content-Length字段会被自动忽略
 * ·基于长连接持续推送动态内容
 * 
 * 
 * 响应体的结构比较有意思，如图所示
 * chunk长度（16进制的数）
 * 第一个chunk的内容
 * 
 * chunk长度（16进制的数）
 * 第二个chunk的内容
 * 。。。。。
 * 0
 * 
 * 最后是留有一个空行，
 * 
 * 以上便是http对定长数据和不定长数据的传输方式
 * 
 * 
 * HTTP如何处理大文件的传输
 * 
 * 对于几百兆甚至G的大文件来说，如果要一口气全部传输完成显然是不现实的，会有大量的等待时间，严重影响用户体验
 * 因此，HTTP针对这一场景，采取了范围请求的解决方案，允许客户端仅仅请求一个资源的一部分
 * 
 * 如何支持
 * 
 * 当然，提前是服务器要支持范围请求，要支持这个功能，就必须加上这样一个响应头：
 * Accept-Ranges: none
 * 
 * 用来告知客户端这边是支持范围请求的
 * 
 * Range字段拆解
 * 
 * 而对于客户端而言，它需要指定请求哪一部分，通过Range这个请求头字段确定，格式为：bytes=x-y
 * 接下来讨论一下这个Range的书写格式
 * 
 * ·0-499表示开始到499个字节
 * ·500表示从500个字节到终点
 * ·-100表示文件的最后100个字节
 * 
 * 服务器收到请求之后，首先验证范围是否合法，如果越界了返回416错误码，否则读取相应片段，返回206状态码
 * 
 * 同时，服务器需要添加Content-Range字段，这个字段的格式根据请求头中Range字段的不同而有所差异
 * 
 * 举例：
 * 
 * //单段数据
 * Range： bytes=0-9
 * 
 * //多段数据
 * Range：bytes=0-9, 30-39
 * 
 * 接下来我们就分别讨论这两种情况
 * 
 * 对于单段数据的请求，返回的响应如下：
 * 
 * HTTP/1.1 206 Partial Content
 * Content-Length: 10
 * Accept-Ranges: bytes
 * Content-Range: bytes 0~9/100
 * 
 * 
 * 多段数据
 * 
 * 接下来我们看看多段请求情况
 * 
 * HTTP中如何处理表单数据的提交？
 * 
 * 在http中，有两种主要的表单提交方式，体现在两种不同的Content-Type取值
 * 
 * ·application/x-www-form-urlencoded
 * `multipart/form-data
 * 
 * 由于表单提交一般是post请求，很少考虑get，因此我们默认将提交数据放在请求体中
 * 
 * application/x-www-form-urlencoded
 * 
 * 对于application/x-www-form-urlencoded格式表单内容，有以下特点：
 * ·其中的数据会被编码为以&分割的键值对
 * ·字符以URL编码方式编码
 * 
 * 转换过程： {a:1, b:2} ---->  a=1&b=2 ---->(如下最终形式)
 * 如：a%3D.......
 * 
 * multipart/form-data
 * 
 * 对于multipart/form-data而言：
 * ·请求头中的Content-Type字段会包含boundary，且boundary的值由浏览器默认指定。
 * 例：Content-Type: multipart/form-data;boundary=---WebkitFormBoundaryRRJKeWfHPGrS4LKe
 * ·数据会分为多个部分，每两个部分之间通过分隔符来分隔，每部分表述均有http头部描述子包体，如Content-Type
 * 最后的分隔符上会加上--表示结束
 * 
 * 值得一提的是，multipart/form-data格式最大的特点是：每一个表单元素都是独立的资源表述。
 * 另外，你可能在写业务的过程中，并没有注意到boundary的存在，如果你打开抓包工具，确实可以看到不同的表单元素
 * 被拆分开了，之所以你感觉不到，是因为浏览器和http给你封装了这一系列操作。
 * 
 * 而且，在实际场景中，对于图片等文件的上传，基本采用了multipart/form-data而不用application/x-www-form-urlencoded，
 * 因为没有必要做URL编码，带来的巨大消耗的同时也占用了更多的空间
 * 
 * 
 * http1.1如何解决http的对头阻塞问题
 * 
 * 什么是http对头阻塞
 * 
 * 从前面的小节可以看到，http传输时基于请求-应答的模式，报文必须是一收一发，但值得注意的是，里面的任务被放在
 * 一个任务队列中串行执行，一旦队首的请求处理太慢，就会阻塞后面请求的处理，这就是队头阻塞问题
 * 
 * 并发连接
 * 
 * 对于一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其他所有的任务。
 * 在RFC2621规定过客户端最多并发2个连接，不过事实上现在的浏览器标准中，这个上限要多很多，chrome中是6个
 * 
 * 但其他，即使提高了并发连接，还是满足不了人们对性能的追求
 * 
 * 域名分片
 * 
 * 一个域名不是可以并发6个长连接吗？那我就多分几个域名
 * 
 * 比如content1.sanyuan.com content2.sanyuan.com
 * 
 * 这样一个sanyuan.com域名下可以分出非常多的二级域名，而他们都指向同样的一台服务器，能够并发的长连接数更多了
 * 事实上也更好的解决了队头阻塞的问题
 * 
 * 
 * 对于cookie了解多少
 * 
 * cookie简介
 * 
 * 前面说到http是一个无状态的协议，每次http请求都是独立、无关的。默认不需要保留状态信息。但是时候需要保存一些
 * 状态，
 * 
 * http为此引入了Cookie。cookie的本质就是浏览器里存储的一个很小的文本文件，内部以键值对的方式来存储。向同一个
 * 域名下发请求，都会携带相同的cookie，服务器拿到cookie进行解析，一遍能拿到客户端的状态。而服务端可以通过响应头
 * 中的set-cookie字段对客户端写入cookie，
 * 
 * //请求头
 * Cookie: a=xxx;b=xxx
 * 
 * //响应头
 * Set-Cookie: a=xxx
 * Set-Cookie: b=xxx
 * 
 * Cookie属性
 * 
 * 生存周期
 * 
 * Cookie的有效期可以通过Expires和Max-Age两个属性来设置
 * ·Expires即过期时间
 * ·Max-Age用一段时间间隔，单位是秒，从浏览器收到报文开始计算
 * 
 * 若Cookie过期，则这个Cookie属性会被删除，并不会发送给服务端
 * 
 * 作用域
 * 
 * 关于作用域也有两个属性：Domain和path，给Cookie绑定了域名和路径，在发请求之前，发现域名或者路径和这两个属性
 * 不匹配，那么就不会带上cookie。值得注意的是，对于路径来说，/表示域名下的任意路径都允许使用Cookie
 * 
 * 安全相关
 * 
 * 如果带上Secure，说明只能通过HTTPS传输cookie
 * 
 * 如果cookie字段带上HttpOnly，那么说明只能通过HTTP协议传输，不能通过js访问。也就是预判XSS攻击的重要手段
 * 
 * 相应的，对于CSRF攻击的预防，也有SameSite属性
 * 
 * SameSite属性可以设置为三个值，Strict、Lax和None
 * 
 * ·在Strict模式下，浏览器完全禁用第三方请求携带cookie。比如请求sanyuan.com网站只能在sanyuan.com域名当中
 * 请求才能携带cookie，其他网站请求都不能
 * 
 * ·在Lax模式，就宽松了一点，但只能在get方法提交表单 或者 a标签发送get请求 的情况下可以携带Cookie，其他情况均不能
 * 
 * ·在None模式下，也就是默认模式，请求会自动携带上Cookie
 * 
 * Cookie的缺点
 * 
 * 1.容量缺陷。Cookie的体积上限只有4kb，只能用来存储少量的信息
 * 2.性能缺陷。Cookie紧跟域名，不管域名下面的某一个地址需不需要cookie，请求都会携带完整的Cookie，这样随着请求数
 * 的增多，其实会造成巨大的性能浪费，因为请求携带了很多不必要的内容。但可以通过Domain和path指定作用域来解决
 * 3.安全缺陷。由于cookie以纯文本的形式在浏览器和服务器中传递，很容易被非法用户截获，然后进行一系列的篡改，在cookie
 * 的有效期内重新发送给服务器，这是相当危险的，另外在httpOnly为false的情况下，Cookie信息能直接通过js脚本来读取
 * 
 * 
 * 如何理解http代理
 * 
 * 我们都知道http是基于请求-响应 模型的协议，一般由客户端发请求，服务器来进行响应
 * 
 * 当然也有特殊的情况，就是代理服务器的情况。引入代理之后，作为代理服务器相当于一个中间人的角色，对于客户端而言
 * 表现为服务器进行响应，对于服务器而言，表现为客户端发请求，具有双重身份
 * 
 * 那么代理服务器到底是用来做什么的呢？
 * 
 * 功能：
 * 1.负载均衡。客户端的请求只会先到达代理服务器，后面到底由多少源服务器，IP都是多少，客户端是不知道的。因此，这个
 * 代理服务器可以拿到请求后，可以通过特定的算法分发给不同的源服务器，让各台服务器的负载尽量均衡，当然，这样的算法
 * 有很多，包括随机算法、轮询、一致性HASH、LRU（最近最少使用）等等，不过这些算法并不是本文的重点，
 * 
 * 2.保障安全。利用心跳机制监控后台的服务器，一旦发现故障机就将其剔除集群。并且对于上下文的数据进行过滤，对非法ip
 * 限流，这些都是代理服务器的工作
 * 
 * 3.缓存代理。将内容缓存到代理服务器，使得客户端可以直接从代理服务器获得而不用到源服务器哪里
 * 
 * 相关头部字段
 * 
 * Via
 * 
 * 代理服务器需要标明字节的身份，在http传输中留下自己的痕迹
 * 
 * 通过 Via字段来记录。举个例子，现在中间有两台代理服务器，在客户端发送请求后会经历这样一个过程
 * 客户端-》代理1-》代理2-》源服务器
 * 
 * 在源服务器收到请求后，会在请求头拿到这个字段：
 * Via: proxy_server1, proxy_server2
 * 
 * 而源服务器响应时，最终在客户端会拿到这样的响应头：
 * Via: proxy_server2, proxy_server1
 * 
 * 可以看到Via中代理的顺序即为http传输中报文传达的顺序。
 * 
 * 
 * X-Forwarded-For
 * 
 * 字面意思就是为谁转发，它记录的是请求方的ip地址（注意，和via区分开），X-Forwarded-For记录的是请求方这一个ip
 * 
 * X-Real-IP
 * 
 * 是一种获取用户真实ip的字段，不管中间经过多少代理，这个字段始终记录最初的客户端ip
 * 
 * 相应的，还有X-Forwarded-Host和X-Forwarded-Proto,分别记录客户端（注意，不包括代理）的域名和协议名称
 * 
 *
 * X-Forwarded-For产生的问题
 * 
 * 前面可以看到，X-Forwareded-For这个字段记录的是请求方的ip，这意味着每经过一个不同的代理，这个名字都要变
 * 从客户端到代理1，从客户端到代理1这个字段的名字是客户端的ip，从代理1到代理2，这个字段的名字是代理1的ip
 * 
 * 但是会产生两个问题：
 * 1.意味着代理必须解析http请求头，然后修改，比直接转发数据性能下降
 * 2.在https通信加密的过程中，原始报文是不允许修改的
 * 
 * 由此产生了代理协议，一般使用明文版本，只需要在http请求行上面加上这样格式的文本即可
 * //PROXY + ICP4/TCP6 + 请求方地址 + 接收方地址 + 请求端口 + 接收端口
 * PROXY TCP 0.0.0.1 0.0.0.2 1111 2222
 * GET / HTTP/1.1
 * 
 * 这样就解决了X-Forwarded-For带来的问题
 * 
 * 
 * 如何理解http缓存及缓存代理？
 * 
 * 关于强缓存和协商缓存的内容，小结
 * 
 * 首先通过Cache-Control验证强缓存是否存在
 * 
 * ·如果强缓存可用，直接使用
 * ·否则进入协商缓存，即发送http请求，服务器通过请求头中的If-Modified-Since或者If-None-Match这些条件请求字段
 * 检查资源是否更新
 *      ·若更新资源，返回资源和200状态码
 *      ·否则，返回304，告诉浏览器直接从缓存获取资源
 * 
 * 为什么产生代理缓存
 * 
 * 对于源服务器来说，它也是有缓存的，比如Redis，Memcache，但对于http缓存来说，如果每次客户端缓存失效都要到源服务器
 * 获取，那给源服务器的压力是很大的。
 * 
 * 由此引入了缓存代理的机制。让代理服务器接管一部分的服务器http缓存，客户端缓存过期后就近到代理缓存中获取，代理缓存
 * 过期了才请求源服务器，这样流量巨大的时候能明显降低源服务器的压力。
 * 
 * 那代理缓存究竟是如何做到的呢？
 * 
 * 总的来说，缓存代理的控制分为两部分，一部分是源服务器端的控制，一部分是客户端的控制
 * 
 * 源服务器的缓存控制
 * 
 * private 和 public
 * 
 * 在源服务器的响应头中，会加上Cache-Control这个字段进行缓存控制字段，那么它的值当中可用加入private或者public
 * 表示是否允许代理服务器进行缓存，前者禁止，后者为允许
 * 
 * 比如对于一些非常私密的数据，如果缓存到代理服务器，别人直接访问代理就可用拿到这些数据，是非常危险的，因此
 * 对于这些数据一般不会允许代理服务器进行缓存，将响应头部的Cache-Control设置为private，而不是public
 * 
 * proxy-revalidate
 * 
 * must-revalidate的意思是客户端缓存过期就去源服务器获取，而proxy-revalidate则表示代理服务器的缓存过期后
 * 到源服务器获取
 * 
 * s-maxage
 * 
 * s是share的意思，限定了缓存在代理服务器中可用存放多久，和限制客户端缓存时间的max-age并不冲突。
 * 
 * 源服务器在响应头中加入这样一个字段
 * 
 * Cache-Control: public, max-age=1000, s-maxage=2000
 * 
 * 相当于源服务器说：我这个响应是允许代理服务器缓存的，客户端缓存过期了到代理中拿，并且在客户端的缓存时间为1000
 * 秒，在代理服务器中的缓存时间为2000s
 * 
 * 
 * 客户端的缓存控制
 * 
 * max-stale 和 min-fresh
 * 
 * 在客户端的请求中，可用加入者两个字段，来对代理服务器的缓存进行宽容和限制操作。
 * 如： max-stale: 5
 * 
 * 表示客户端到代理服务器上拿缓存的时候，即使代理缓存过期了也不要紧，只要过期时间在5秒内，还是可用从代理中获取的
 * 
 * 如：min-fresh: 5
 * 
 * 表示代理缓存需要一定的新鲜度，不要等到缓存刚好过期再拿，一定要在到期前5秒时间拿，否则拿不到
 * 
 * 
 * only-if-cached
 * 
 * 这个字段加上后表示客户端只会接收代理缓存，而不会接收源服务器的响应，如果代理缓存无效，则直接返回504（Gateway Timeout）
 * 
 * 
 * 什么是跨域？浏览器如何拦截响应？
 * 
 * 在前后端分离的项目中，经常会遇到跨域的问题，即Ajax请求发出去了，服务端也成功响应了，前端就是拿不到响应。
 * 
 * 什么是跨域
 * 
 * 浏览器遵循同源策略（scheme（协议）、host（主机）和port（端口）都相同则为同源）。非同源站点有这样一些限制
 * 
 * ·不能读取和修改对方的dom
 * ·不能访问对方的Cookie、indexDb和LocalStorage
 * ·限制XMLHttpRequest请求
 * 
 * 当浏览器向目标URI发起Ajax请求时，只要当前URL和目标URL不同源，则产生跨域，被称为跨域请求
 * 
 * 跨域请求的响应一般会被浏览器拦截，注意，是被浏览器拦截，响应其实是成功到达了客户端。这个拦截是如何发送的呢？
 * 
 * 首先要知道的是，浏览器是多进程的，以chrome为例，进程组成如下：
 * 
 * 渲染进程                 插件进程
 * Render Process           Plugin Process
 * 
 * 浏览器主进程             GPU进程
 * Browser Process          GPU Process
 * 
 * webkit渲染引擎和v8引擎都在渲染进程当中
 * 
 * 当xhr.send被调用，即Ajax请求准备发送的时候，其实还只是在渲染进程的处理。为了防止黑客通过脚本触碰系统资源，
 * 浏览器将每个渲染进程装进了沙箱，并且为了防止CPU芯片一直存在Spectre和Meltdown漏洞，采取了站点隔离的手段，
 * 给每一个不同的站点（一级域名不同）分配了沙箱，互不干扰
 * 
 * 在沙箱当中的渲染进程是没办法发送网络请求的，那怎么办呢，只能通过网络进程来发送。那这样就涉及到了进程间的通信
 * （IPC inter Process Communication）了。接下来我们看看chromium当中进程间通信是如何完成的，在chromium源码
 * 中的调用顺序如下：
 *                                                  Listener
 *                                                      |
 *                                                      |
 *                                                      |
 *                                                 ChannelProxy/
 *                                                 SyncChannel
 *                                                      |
 *                                                      |
 * sender                                               |     
 * |                                                channelReader
 * | send                                               |     
 * |                                                    |
 * ChannelProxy/                                        |            
 * SyncChannel                                      channelPosix        
 * |                                                    |
 * | send                                               |       
 * |                                                    |
 * channelPosix                                      Libevent              
 * |                                                    |
 * | write                                              | EV_READ    
 * |                                                    |
 * -----------------------------------------------------------------
 *                          Unix Domain Socket
 * 
 * 总的来说就是利用Unix Domain Socket套接字，配合事件驱动的高性能网络并发库libevent完成进程的IPC过程
 * 
 * 好，现在数据传递给了浏览器主进程，主进程接收到后，才真正的发出相应的网络请求
 * 
 * 在服务端处理完数据后，将响应返回，主进程检查到跨域，且没有CORS响应头，将响应体全部丢掉，并不会发送给
 * 渲染进程。着就达到了拦截的目的
 * 
 * 接下来说说解决跨域问题的几种方案
 * 
 * CORS其实是w3c的一个标准，全称是跨域资源共享。它需要浏览器和服务器的共同支持，具体来说，非ie和ie10以上支持cors
 * 服务器需要附加特定的响应头，后面具体拆解，不过在弄清CORS的原理之前，我们需要清除两个概念：简单请求和非简单请求
 * 
 * 浏览器根据请求方法和请求头的特定字段，将请求做了一下分类，具体来说规则是这样的，凡是满足下面条件的就是简单请求
 * 
 * ·请求方法为GET, POST或者HEAD
 * ·请求头的取值范围：Accept、Accept-Language, Content-Language, Content-Type(只限于三个值
 *  application/x-www-form-urlencoded, multipart/form-data, text-plain
 * )
 * 
 * 浏览器画了这样一个圈，在这个圈里面的就是简单请求，圈外面的就是非简单请求，然后针对着两种不同的请求进行不同的处理
 * 
 * 简单请求
 * 
 * 发出请求之前浏览器做了什么
 * 
 * 他会自动在请求头中，添加一个origin字段，用来说明请求来自哪个源。服务器拿到请求之后，在回应时对应的添加
 * Access-Control-Allow-Origin字段，如果Origin不在这个字段范围中，那么浏览器就会将响应拦截
 * 
 * 因此Access-Control-ALlow-Origin字段是服务器用来决定浏览器是否拦截这个响应，这是必需的字段，于此同时，
 * 其他一些可选的功能性字段，用来描述如果不会拦截，这些字段将会发挥各自的作用
 * 
 * Access-Control-Expose-Headers。这个字段时给XMLHttpRequest对象赋能，让他不仅可用拿到基本的6个 字段（
 * 包括Cache-Control, Content-Length, Content-Type, Expries, Last-Modified和Pragma，还能拿到这个字段
 * 响应声明的响应头字段。比如这样设置
 * ）ccess-Control-Expose-Header: aaa
 * 
 * 那么前端可用通过XMLHttpRequest.getResponseHeader('aaa')拿到这个aaa字段
 * 
 * 非简单请求
 * 
 * 非简单请求和简单请求会有些不同，体现在两个方面：预检请求和响应字段
 * 
 * 以put为例
 * 
 * var url = 'http://xxx.com'
 * var xhr = new XHMHttpRequest()
 * xhr.open('put', rul, true)
 * xhr.setRequestHeader('x-Custom-header', 'xxx')
 * rxh.send()
 * 
 * 
 * {}
 * 
 * 当这段代码执行后，首先会发送预检请求，这个预检请求的请求行和请求体是下面这个格式：
 * 
 * OPTIONS / HTTP/1.1
 * Origin: 当前地址
 * Host: xxx.com
 * Access-Control-Request-Method: PUT
 * Access-Control-Request-Headers: X-Custom-Header
 * 
 * 
 * 预检请求的方法是Options, 同时会加上Origin源地址和Host目标地址，这个很简单同时也会加上两个 关键字段
 * ·Access-Control-Request-Method:，列出CORS请求用到哪个HTTP方法
 * ·Access-Control-Request-Headers: 指定CORS请求要加上什么请求头
 * 
 * 这是预检请求。接下来是响应字段，响应字段也分为两部分，一部分是对预检请求的响应，一部分是对CORS请求的响应
 * 
 * 预检请求的响应格式如下:
 * 
 * HTTP/1.1 200 OK
 * Access-Control-Allow-Origin: *
 * Access-Control-Allow-Methods: GET, POST, PUT
 * Access-Control-Allow-Headers: X-Custom-Header
 * Access-Control-Allow-Credenials: true
 * Access-Control-Max-Age: 1728000
 * Content-Type: text/html; charset=utf-8
 * Content-Encoding: gzip
 * Content-Length: 0
 * 
 * 其中有这样几个关键的响应头字段：
 * ·Access-Control-Allow-Origin:表示可用允许请求的源，可以填写具体的源名称，也可以填*表示允许任意源请求
 * ·Access-Control-Allow-Methods:表示允许的请求方法列表
 * ·Access-Control-Allow-Headers: 表示允许发送的请求头字段
 * ·Access-Control-Max-Age: 预检请求的有效期，在此期间，不用发出另一条预检请求
 * 
 * 当预检请求的响应返回后，如果请求不满足响应头的条件，则触发XMLHttpRequest的onerror方法，当然后面真正的
 * CORS请求也不会发出去了。
 * 
 * CORS请求的响应。绕了这么一大圈，到了真正的CORS请求就容易多了，现在它和简单请求的情况是一样的。浏览器自动
 * 加上Origin字段，服务器响应头返回Access-Control-Allow-Origin
 * 
 * 
 * JSONP
 * 
 * 虽然XMLHttpRequest对象遵循同源策略，但是script标签不一样，它可以通过src上填写目标地址从而发出GET请求，
 * 实现跨域请求并拿到响应。这也就是jsonp的原理
 * 
 */

const jsonp = ({ url, params, callbackName }) => {
    const generateURL = () => {
        let dataStr = ''
        for(let key in params){
            dataStr += `${key}=${params[key]}$`
        }
        dataStr += `callback=${callbackName}`
        return `${url}?${dataStr}`
    }

    return new Promise((resolve, reject) => {
        callbackName = callbackName || Math.random().toString().replace(',', '')
        let scriptElement = document.createElement('script');
        scriptElement.src = generateURL()
        document.body.appendChild(scriptElement)

        window[callbackName] = (data) => {
            resolve(data)

            document.body.removeChild(scriptElement)
        }
    })
}

/**
 * 和CORS相比，jsonp最大的优势在于兼容性好，IE低版本不能使用CORS但可以使用JSONP，缺点也很明显，请求方法单一
 * 只支持get请求
 * 
 * Nginx
 * 
 * Nginx是一种高性能的反向代理服务器，可以用来轻松解决跨域问题
 * 
 * client                          |
 *                                 |
 *                                 |
 * client      -->  Proxy(VPN) --> | --> server
 *                                 |
 *                                 |
 * client                          |    正向代理
 * 
 * -------------------------------------------------
 * 反向代理
 *                                  | --> Server
 *                                  |     
 * client   --->   Proxy(nginx) --> | --> Server
 *                                  |    
 *                                  | --> Server
 * 
 * 正向代理帮助客户端访问客户端访问不到得服务器，然后将结果返回给客户端
 * 
 * 反向代理拿到客户端得请求，将请求转发给其他服务器，主要得场景是维持服务器集群得负载均衡，换句话说，反向代理
 * 帮其他得服务器拿到请求，然后选择一个合适得服务器，将请求转交给它
 * 
 * 因此，两者得区别就很明显了，正向代理服务器是帮助客户端做事，而反向代理服务器是帮其它服务器做事
 * 
 * 那nginx是如何来解决跨域问题得呢？
 * 
 * 比如说现在客户端得域名为client.com, 服务器得域名为server.com,客户端向服务端发送ajax请求，当然会跨域了，
 * 那这个时候让nginx登场
 * 
 * server {
 *  listen 80;
 *  server_name client.com;
 *  location /api {
 *      proxy_pass server.com
 *  }
 * }
 * 
 * Nginx相当于起了一个跳板机，这个跳板机得域名是client.com，让客户端首先访问client/api，这当然没有跨域，然后
 * Nginx服务器作为反想代理，将请求转发给server.com，当响应返回时，又将响应给到客户款，这就完成了整个跨域请求得过程
 * 
 * 其实还有一些不太常用得方式，比如postMessage，当然WebSocket也是一种方式，但是已经不属于http得范畴了，另外一些
 * 奇淫技巧
 * 
 * TLS1.2握手得过程是怎样得
 * 
 * 之前谈到http是明文传输得协议，传输报文对外完全透明，非常不安全，那如何进一步保证安全性呢？
 * 
 * 由此产生了https，其实它并不是一个新得协议而是在http下面增加了一层SSL/TLS协议，简单得讲，HTTPS = HTTP + SSL/TLS
 * 
 * 那什么是ssl/tls呢
 * 
 * ssl即安全套接层（Secure Sockets Layer），在OSI七层中处于会话层，之前SSL出过三个版本，当他发展到第三大版本得时候
 * 才被标准化，称为TLS(传输层安全，Transfer Layer Secure),并当作TLS1.0得标准版本，准确得说，TLS1.0 == SSL1.3
 * 
 * 现在主流得版本是TLS/1.2,之前得TLS1.0, TLS1.1都被认为是不安全得，在不久得将来将会被完全淘汰。因此我们接下来
 * 讨论TLS1.2，当然2018年退出了更加优秀得TLS1.3大大优化了TLS握手过程
 * 
 * TLS1.2握手过程
 * 
 * 浏览器                                       服务器
 * |  -->  client_random TLS版本 加密套件列表   -->   |                                          
 * |                                                |   
 * |<-- server_random server_params 确认TLS版本 <--  |
 * |    使用的加密套件列表 服务器使用的证书            |                                 
 * |                                                |    
 * 验证数字证书                                      |
 * |                                                |
 * |通过                                            |        
 * |                                                |   
 * 生成                                             |    
 * client_params                                    |
 * |                                                |     
 * |->      传递client_params                   --> |                              
 * |                                                |    
 * ECDHE计算                                        ECDHE计算
 * pre_random                                       pre_random
 * |                                                |        
 * 计算出secret                                     计算出secret                
 *  <--  之后的传输都是用secret作为密钥进行加密  -->                                      
 *                                                      
 * step1: client Hello
 * 
 * 首先，浏览器发送client_random、TLS版本、加密套件列表
 * 
 * client_random用来最终生成secret的一个参数
 * 
 * 加密套件列表
 * 
 * TLS_ECDHE_WITH_AES_128_GCM_SHA256
 * 
 * 意思是TLS握手过程中，使用ECDHE算法生成pre_random。128位的AES算法进行对称加密，在对称加密的过程中
 * 使用主流的GCM分组模式，因为对称加密中很重要的一个问题是如何分组。最后是一个哈希摘要算法，采用SHA256
 * 
 * 值得解释一下的是这个哈希算法，试想这样一个场景，服务端现在给客户端发消息来了，客户端不知道此时的消息
 * 到底是服务端发送的，还是中间人伪造的消息？现在引入这个哈希摘要算法，将服务端的证书通过这个算法生成
 * 一个摘要（可以理解为比较短的字符串），用来标识这个服务端的身份，用私钥加密后把加密后的标识和自己的公钥
 * 传给客户端。客户端拿到这个公钥来解密，生成另一份摘要。两个摘要进行对比。如果相同则确认服务端身份。
 * 这也就是所谓的数字签名的原理。其中除了哈希算法，最重要的过程是私钥加密，公钥加密
 * 
 * step2 Server Hello
 * 
 * 可以看到服务器一口气给了客户端回复了非常多的内容
 * 
 * server_random也最后生成了secret的一个参数，同时确认TLS版本、需要使用加密套件和自己的证书，这都不难理解
 * 那剩下server_params是干嘛的呢？
 * 
 * 
 * step3 client验证证书，生成secret
 * 
 * 客户端验证服务器端传过来的证书和签名是否通过，如果验证通过，则传递client_params这个参数给服务端
 * 
 * 接着客户端通过ECDHE算法计算出pre_random，其中传入d两个参数server_params client_params。现在你
 * 应该清除这两个参数的作用了吧，由于ECDHE基于椭圆曲线离散对数，这两个参数也称为椭圆曲线的公钥
 * 
 * 客户端现在拥有了client_random\ server_random pre_random接下来将这个三个数通过一个伪随机数来计算出
 * 最终的secret
 * 
 * step4 server生成secret
 * 
 * 刚刚客户端不是传了client_params过来吗
 * 
 * 现在服务端开始用ECDHE算法生成pre_random，接着用和客户端相同的伪随机数函数生成最后的secret
 * 
 * 
 * 注意事项：
 * 
 * TLS的过程基本上讲完了，但还又两点需要注意
 * 
 * 第一：实际上TLS握手是一个双向认证的过程，从step1中可以看到，客户端有能力验证服务端的身份，那服务端
 * 能不能验证客户端的身份呢？
 * 
 * 当然是可以的，具体来说，在第三步中，客户端传送client_params，实际上给服务器传了一个验证消息，让
 * 服务器将相同的验证流程走一遍（哈希摘要+私钥加密+公钥解密），确认客户端的身份
 * 
 * 第二：当客户端生成secret后，会给服务端发送一个收尾消息，告诉服务器之后都用对称加密，对称加密的算法
 * 就是第一次约定的。服务器生成完secret也会想客户端发送一个收尾消息，告诉客户端以后就直接用对称加密来
 * 通信
 * 
 * 这个收尾的消息包括两部分，一部分是Change Cipher Spec，意味着后面加密传输了，另一个是Finished消息
 * 这个消息是对之前所发送的数据做摘要，对摘要进行加密，让对方验证一下
 * 
 * 双方都验证通过后，握手才正式结束，后面的http正式开始传输加密报文
 * 
 * RSA和ECDHE握手过程的区别
 * 
 * 1.ECDHE握手，也就是主流的TLS1.2握手中，使用ECDHE实现pre_random的加密没有解密，没有用到RSA
 * 2.使用ECDHE还有一个特点，就是客户端发送完收尾消息后可以提前抢跑，直接发送http报文，节省了一个RTT，
 * 不必等到收尾消息到达服务端，然后等服务端返回收尾消息。直接开始发请求，这也叫TLS False Start
 * 
 * TLS1.3做了哪些改进
 * 主要分为这几部分：强化安全、提高性能
 * 
 * 性能提升
 * 
 * 浏览器                                       服务器
 *        client_params, client_random, TLS版本 --->
 *        加密套件列表
 * 
 *   <--- server_random, server_params，确认TLS版本
 *        使用的加密套件列表、服务器使用的证书      
 *                                                 |
 * 验证数字证书                                  ECDHE计算pre_random
 * |通过                                           |
 * |                                            计算出secret
 * ECDHE计算
 * pre_random
 * |
 * 计算出
 * secret
 * 
 *        之后的传输都使用secret作为密钥进行加解密
 * 
 * 
 * 大体的方式和TLS1.2差不多，不过和TLS1.2相比少了一个RTT，服务器不必等待对方验证数字证书之后才拿到
 * client_params，而是直接在第一次握手的时候就能够拿到，拿到之后立即计算secret，节省了之前不必要的
 * 等待时间。同时，也意味着在第一次握手的时候客户端需要传送更多的信息，一口气给传完
 * 
 * 这种TLS1.3握手方式也被叫做1-RTT握手。但其实这种1-RTT握手还是有一些优化看空间--优化
 * 
 * 会话复用
 * 
 * 会话复用有两种方式：SessionID 和 Session Ticket
 * 
 * 最先说说最早出现的SessionID,具体的做法是客户端和服务器端首次连接后各自保存会话的ID，并存储会话密钥
 * 当再次连接时，客户端发送ID过来，服务器查找这个ID是否存在，如果找到了直接复用之前的会话状态，会话密钥
 * 不用重新生成，直接用原来的那份
 * 
 * 但这种方式也存在一个弊端，就是当客户但数量庞大时，对服务端的存储压力非常大
 * 
 * 因而出现了第二种方式--Session Ticket 它的思路就是：服务端的压力大，那就把压力分摊给客户端。具体来说
 * 双方连接成功后，服务端加密会话信息，用Session Ticket消息发送给客户端，让客户端保存下来。下次重连的时候
 * 就把这个Ticket进行解密，验证它过没过期，如果没有过期那就直接恢复之前的会话状态
 * 
 * 这种方式虽然减小了服务端的压力，但时带来了安全问题，即每次用一个固定的密钥来解密Ticket数据，一旦黑客
 * 拿到这个密钥，之前所有的历史记录也被破解了。因此为了避免这样的问题，密钥需要定期更换
 * 
 * 总的来说，这些会话复用技术在保证1-RTT的同时，也节省了生成会话密钥这些算法所消耗的时间
 * 
 * psk
 * 
 * 刚都说了1-RTT优化，那能不能0-RTT优化呢？
 * 
 * 答案时可以的，做法其实很简单，在发送Session Ticket的同时带上应用数据，不用等待服务器确认
 * 这种方式被称为Pre_share key即PSK
 * 
 * 这种方式虽然方便，但是也带来了安全问题。中间人截获PSK的数据，不断向服务器重复发类似于TCP第一次
 * 握手携带的数据，增加了服务器被攻击的风险
 * 
 * HTTP/2有哪些改进
 * 
 * 由于HTTPS在安全方面已经做的非常好了http改进的关注点放在了性能方面，对于http而言，它对于性能的
 * 提升主要在于两点
 * 
 * ·头部压缩
 * ·多路复用
 * 
 * 当然还有一些颠覆性的功能实现
 * ·设置请求优先级
 * ·服务器推送
 * 
 * 这些重大的提升本质也是为了解决http本身的问题而产生的。
 * 
 * 头部压缩
 * 
 * 在http/1.1之前的时代，请求体一般会有相应的压缩编码过程，通过Content-Encoding头部字段来指定
 * 但你有没有想过头部字段本身的压缩呢？当请求字段非常复杂的时候，尤其对于GET请求，请求报文几乎全是
 * 请求透，这个时候还是存在非常大的请求空间的。HTTP/2针对头部字段，也采用了对应的压缩方法-HPACK
 * 对请求头进行压缩
 * 
 * HPACK算法是专门为HTTP/2服务的，它主要的亮点有两个：
 * ·首先是在服务器和客户端之间建立哈希表，将用到的字段存放在这张表种。那么在传输的时候对于之前出现
 * 过的值，只需要把索引传给对方即可，对方拿到索引表就行了。这种传索引的方式，可以说让请求头字段得到
 * 极大程度的精简和复用
 * 
 * ·其次是对于整数和字符串进行哈夫曼编码，哈夫曼编码的原理就是先将所有出现的字符建立一张索引表，
 * 然后让出现次数多的字符对应的索引尽可能短，传输的时候传输这样的索引序列。可以达到非常高的压缩率
 * 
 * 多路复用
 * 
 * HTTP对头阻塞
 * 
 * 我们之前讨论了HTTP对头阻塞的问题，其根本原因在于http基于请求-响应的模型在同一个TCP长连接中，
 * 前面的请求没有得到响应，后面的请求就会被阻塞
 * 
 * 后面我们又讨论用并发连接和域名分片的方式来解决这个问题，但这并没有真正的从http本身的层面解决问题
 * 只是增加了TCP连接，分摊风险而已。而这么做也又弊端，多条tcp连接会竞争有限的带宽，让真正优先级搞得
 * 请求不能优先处理
 * 
 * 而http/2变从HTTP协议本身解决了对头阻塞得问题。注意这里并不是指TCP对头阻塞，而是HTTP队头阻塞，
 * 两者并不是一回事。TCP得队头阻塞是在数据包层面单位是数据包，前一个报文没有收到便不会将后面收到
 * 得报文传给http，而http得队头阻塞时在http请求-响应层面，前一个请求没处理完，后面得请求就要堵塞
 * 
 * http/2如何解决队头阻塞
 * 
 * 二进制分帧
 * 
 * 首先，http/2认为明文传输对机器而言太麻烦了，不方便计算机得解析因为对于文本而言会有多义性得字符
 * 比如回车换行到底是内容还时分隔符，在内部需要时要用到状态机识别，效率比较低，对于HTTP/2干脆把
 * 报文全部转换成二进制形式，全部传输01串，方便机器解析
 * 
 * 原来Headers + Body得报文格式如今被拆分成了一个个二进制帧，用Headers帧存放头部字段， Data帧存放
 * 请求体数据。分帧之后，服务器看到得不再是一个个完整得HTTP请求报文，而是一堆乱序得二进制帧，。这些
 * 二进制帧不存在先后关系，因此也就不会排队等待，也就不会有队头阻塞问题
 * 
 * 通信双方都可以给对方发送二进制帧，这种二进制帧得双向传输得序列也叫做流，HTTP/2用流来在一个TCP连接
 * 上来进行多个数据帧得通信，这就是多路复用对的概念
 * 
 * 既然是乱序首发，那最后如何处理这些乱序得数据帧呢？
 * 
 * 首先要明确的是，所谓的乱序，指的是不同ID的Stream是乱序，但是同一个Stream ID的帧一定是按顺序传输的
 * 二进制帧到达后将对方的Stream ID相同的二进制帧组成完整的请求报文和响应报文
 * 
 * 推送服务器
 * 
 * 
 * 
 * 
 * 
 * 
 * 
 */